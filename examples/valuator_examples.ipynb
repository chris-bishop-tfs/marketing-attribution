{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964efaec",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "Provide some examples of how to use the `attribution` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44bac104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'identifier': 1, 'impressions': ['B', 'A'], 'value': 944},\n",
       " {'identifier': 2, 'impressions': ['B', 'A'], 'value': 952},\n",
       " {'identifier': 3, 'impressions': ['B', 'A'], 'value': 776},\n",
       " {'identifier': 4, 'impressions': ['C', 'B', 'A'], 'value': 1389},\n",
       " {'identifier': 5, 'impressions': ['C', 'B'], 'value': 717},\n",
       " {'identifier': 6, 'impressions': ['B'], 'value': 628},\n",
       " {'identifier': 7, 'impressions': ['A'], 'value': 332},\n",
       " {'identifier': 8, 'impressions': ['C', 'A'], 'value': 433},\n",
       " {'identifier': 9, 'impressions': ['C'], 'value': 199},\n",
       " {'identifier': 10, 'impressions': ['A'], 'value': 68}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load example data\n",
    "import json\n",
    "\n",
    "with open('../data/example_data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Inspect subset of data\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710b600",
   "metadata": {},
   "source": [
    "### Attribution Methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3758ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 875995, 'B': 3503081, 'C': 2741803}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from attribution.valuator import build_valuator\n",
    "\n",
    "valuator = build_valuator(data, 'first_touch')\n",
    "\n",
    "valuator.valuate_treatments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20888671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 6122920, 'B': 915703, 'C': 82256}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuator = build_valuator(data, 'last_touch')\n",
    "\n",
    "valuator.valuate_treatments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c726d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/05/06 21:02:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/06 21:02:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/05/06 21:02:49 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "valuator = build_valuator(data, 'shapley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08b26f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': 3159066.0, 'B': 2890174.9999999995, 'C': 1071638.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valuator.valuate_treatments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8154308e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7120879.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3159066.0 + 2890174.9999999995 + 1071638.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22c0bccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7120879"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6122920 + 915703 + 82256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "077a9b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[identifier: string, treatment_set: array<string>, value: bigint, A: int, B: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from attribution.audience import build_audience\n",
    "\n",
    "audience = build_audience(data)\n",
    "\n",
    "# # audience.to_pyspark()\n",
    "# a = build_audience([dict(identifier='1', **audience.members[0].journey.to_dict())])\n",
    "# j = a.members[0].journey\n",
    "\n",
    "# list(j.impressions)\n",
    "# j.impressions = list(j.impressions)\n",
    "\n",
    "# build_audience([dict(identifier='1', **j.to_dict())]).to_pyspark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b4d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attribution.audience import build_audience\n",
    "from attribution.journey import build_journey_set\n",
    "\n",
    "audience = build_audience(data)\n",
    "\n",
    "treatments = audience.treatments\n",
    "\n",
    "possible_journeys = build_journey_set(treatments)\n",
    "\n",
    "# possible_journeys\n",
    "# Massage into a data frame with identifiers, etc.\n",
    "#  We'll leverage an \"audience\" to do this\n",
    "for i, j in enumerate(possible_journeys):\n",
    "    if i == 0:\n",
    "        data = list()\n",
    "\n",
    "    # Append a sequential identifier\n",
    "    _data = dict(\n",
    "        identifier=i,\n",
    "        **j.to_dict()\n",
    "    )\n",
    "\n",
    "data.append(_data)\n",
    "\n",
    "journey_set = build_audience(data).to_pyspark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = build_valuator(data, 'shapley')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01986950",
   "metadata": {},
   "outputs": [],
   "source": [
    "audience_data = builder.audience.to_pyspark()\n",
    "\n",
    "attribution_data = audience_data\n",
    "\n",
    "treatments = builder.audience.treatments\n",
    "\n",
    "from attribution.journey import build_journey_set\n",
    "\n",
    "possible_journeys = build_journey_set(treatments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4045f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_journeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e89e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Massage into a data frame with identifiers, etc.\n",
    "#  We'll leverage an \"audience\" to do this\n",
    "for i, j in enumerate(possible_journeys):\n",
    "    if i == 0:\n",
    "        data = list()\n",
    "\n",
    "      # Append a sequential identifier\n",
    "    _data = dict(identifier=i, **j.to_dict())\n",
    "    data.append(_data)\n",
    "    \n",
    "a = build_audience(data)\n",
    "\n",
    "row_data = []\n",
    "for m in a.members:\n",
    "    row_data.append(m.to_row())\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as sf\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark.createDataFrame(row_data).withColumnRenamed('impressions', 'treatment').select(sf.posexplode('treatment'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
